{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from gensim.models import word2vec\n",
    "from bs4 import BeautifulSoup  # To clean the text from the html\n",
    "import re  # Regular Expressions\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with dataset of reviews on women's clothes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age Title  \\\n",
       "0           0          767   33   NaN   \n",
       "1           1         1080   34   NaN   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "\n",
       "   Positive Feedback Count Division Name Department Name Class Name  \n",
       "0                        0     Initmates        Intimate  Intimates  \n",
       "1                        4       General         Dresses    Dresses  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Womens Clothing E-Commerce Reviews.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only need the column with the review text since our task is to train the w2v model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23486"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data=data['Review Text']).rename(columns={'Review Text': 'review'})\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions that create tokens from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=False ):\n",
    "    review = re.sub(r\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \" \", review)\n",
    "    review_text = BeautifulSoup(review, \"html.parser\").get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stops = stopwords.words(\"english\")\n",
    "        words = [w for w in words if not w in stops]\n",
    "    return(words)\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "def review_to_sentences(review, tokenizer=tokenizer, remove_stopwords=False):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Absolutely wonderful - silky and sexy and comf...\n",
       "1    Love this dress!  it's sooo pretty.  i happene...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"review\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd65cf26270540d88fd3492fbe19a9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23486 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences = list(tqdm(map(review_to_sentences, data[\"review\"].astype(str)), total=len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have lists of words that make up the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23486\n",
      "[[['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable']], [['love', 'this', 'dress'], ['it', 's', 'sooo', 'pretty'], ['i', 'happened', 'to', 'find', 'it', 'in', 'a', 'store', 'and', 'i', 'm', 'glad', 'i', 'did', 'bc', 'i', 'never', 'would', 'have', 'ordered', 'it', 'online', 'bc', 'it', 's', 'petite'], ['i', 'bought', 'a', 'petite', 'and', 'am'], ['i', 'love', 'the', 'length', 'on', 'me', 'hits', 'just', 'a', 'little', 'below', 'the', 'knee'], ['would', 'definitely', 'be', 'a', 'true', 'midi', 'on', 'someone', 'who', 'is', 'truly', 'petite']]]\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))\n",
    "print(sentences[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['absolutely', 'wonderful', 'silky', 'and', 'sexy', 'and', 'comfortable'],\n",
       " ['love', 'this', 'dress'],\n",
       " ['it', 's', 'sooo', 'pretty']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_sentences = [item for sublist in sentences for item in sublist]\n",
    "flat_sentences[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10.7 s\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = word2vec.Word2Vec(flat_sentences, workers=4, vector_size=300, min_count=10, window=10, sample=1e-3, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has 3.3k unique vectorized words in it's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3364\n"
     ]
    }
   ],
   "source": [
    "print(len(model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model has been trained on the data from the women's clothing review, we can perform some operations on the vectorized words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, it is quite entertaining that if you subtract the word \"sexy\" from the phrase \"small dress\", similar words would be \"large\", \"medium\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('large', 0.6205908060073853) ('l', 0.5897884368896484) ('medium', 0.589218258857727)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar(positive=[\"dress\", \"small\"], negative=[\"sexy\"], topn=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we get the plural from the singular for heel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('heels', 0.6841935515403748)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar(positive=[\"heel\", \"women\"], negative=[\"woman\"], topn=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has the following most similar words to the word USA :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cheaply', 0.8089789152145386) ('poorly', 0.6855989098548889) ('well', 0.6430597901344299)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar(\"usa\", topn=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we give a sequence of words and ask the model to eliminate the superfluous (most distant from the others, or unlike) word, we get the following quite logically explainable result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elegant\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.doesnt_match(\"lagre tall small elegant tight\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main limitation of the model is that its interpretation of words and synonyms depends on the texts it receives for training. For example, for the word \"star\" its direct meaning as a celestial luminary will be very far away, but the figurative meanings will be closer, since these are the meanings that occur in our reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('stars', 0.7087801098823547)\n",
      "('major', 0.674744725227356)\n",
      "('rating', 0.6625295281410217)\n",
      "('minor', 0.6463609933853149)\n",
      "('four', 0.6169639229774475)\n",
      "('negative', 0.6142308115959167)\n",
      "('reason', 0.608757734298706)\n",
      "('five', 0.5718724727630615)\n",
      "('solved', 0.5523854494094849)\n",
      "('gave', 0.5501779317855835)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar(\"star\", topn=10), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Star\" is almost twice as close to \"rating\" as to \"shine\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40836945"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('star', 'shine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And almost six times farther away from \"sky\" than \"rating\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08556241"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('star', 'sky')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Retraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a pre-trained model and further train it on other data, which is very convenient. This will allow us to add new words to an existing dictionary and change the vector values of existing ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with, let's take a couple of words that are likely to change after training and memorize synonyms for them. Since we will be learning from Alice in Wonderland, it is likely that the meanings of the words \"illusion\" and \"white\" may change due to frequent references in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hiding', 0.6951606869697571)\n",
      "('empire', 0.6687750220298767)\n",
      "('bulge', 0.6579235196113586)\n",
      "('appearance', 0.6348645091056824)\n",
      "('volume', 0.6276013851165771)\n",
      "('defined', 0.6257961392402649)\n",
      "('effect', 0.6207180023193359)\n",
      "('creating', 0.6204461455345154)\n",
      "('fullness', 0.6187328696250916)\n",
      "('accentuate', 0.6186639666557312)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar(\"illusion\", topn=10), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('black', 0.8461518883705139)\n",
      "('navy', 0.767144501209259)\n",
      "('colored', 0.7560238242149353)\n",
      "('grey', 0.7489383816719055)\n",
      "('cream', 0.748173177242279)\n",
      "('gray', 0.7364131808280945)\n",
      "('ivory', 0.732673704624176)\n",
      "('red', 0.7277088165283203)\n",
      "('brown', 0.7240748405456543)\n",
      "('beige', 0.6978108286857605)\n"
     ]
    }
   ],
   "source": [
    "print(*model.wv.most_similar(\"white\", topn=10), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's process the words as we did last time, dividing them into sentences and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[\"alice's\", 'adventures', 'in', 'wonderland', \"alice's\", 'adventures', 'in', 'wonderland', 'lewis', 'carroll', 'the', 'millennium', 'fulcrum', 'edition', '3.0', 'chapter', 'i', 'down', 'the', 'rabbit-hole', 'alice', 'was', 'beginning', 'to', 'get', 'very', 'tired', 'of', 'sitting', 'by', 'her', 'sister', 'on', 'the', 'bank', 'and', 'of', 'having', 'nothing', 'to', 'do', 'once', 'or', 'twice', 'she', 'had', 'peeped', 'into', 'the', 'book', 'her', 'sister', 'was', 'reading', 'but', 'it', 'had', 'no', 'pictures', 'or', 'conversations', 'in', 'it', 'and', 'what', 'is', 'the', 'use', 'of', 'a', \"book,'\", 'thought', 'alice', 'without', 'pictures', 'or', \"conversation?'\"], ['so', 'she', 'was', 'considering', 'in', 'her', 'own', 'mind', 'as', 'well', 'as', 'she', 'could', 'for', 'the', 'hot', 'day', 'made', 'her', 'feel', 'very', 'sleepy', 'and', 'stupid', 'whether', 'the', 'pleasure', 'of', 'making', 'a', 'daisy-chain', 'would', 'be', 'worth', 'the', 'trouble', 'of', 'getting', 'up', 'and', 'picking', 'the', 'daisies', 'when', 'suddenly', 'a', 'white', 'rabbit', 'with', 'pink', 'eyes', 'ran', 'close', 'by', 'her']]\n"
     ]
    }
   ],
   "source": [
    "with open(\"alice_in_wonderland.txt\", 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = re.sub('\\n', ' ', text)\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "punct = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~„“«»†*—/\\-‘’'\n",
    "clean_sents = []\n",
    "\n",
    "for sent in sents:\n",
    "    s = [w.lower().strip(punct) for w in sent.split()]\n",
    "    clean_sents.append(s)\n",
    "\n",
    "print(clean_sents[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model for later loading for pre-training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"clothes_reviews.model\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our model again, this time into a different variable. Run the training on Alice in Wonderland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70570, 132360)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_retrained = word2vec.Word2Vec.load(model_path)\n",
    "\n",
    "model_retrained.build_vocab(clean_sents, update=True)\n",
    "model_retrained.train(clean_sents, total_examples=model_retrained.corpus_count, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of the results obtained after retraining the model on known words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model | Retrained model\n",
      "               |\n",
      "        hiding | hiding\n",
      "        empire | empire\n",
      "         bulge | bulge\n",
      "    appearance | volume\n",
      "        volume | defined\n",
      "       defined | creating\n",
      "        effect | fullness\n",
      "      creating | accentuate\n",
      "      fullness | favors\n",
      "    accentuate | silhouette\n"
     ]
    }
   ],
   "source": [
    "wrds1 = [words[0] for words in model.wv.most_similar(\"illusion\", topn=10)]\n",
    "wrds2 = [words[0] for words in model_retrained.wv.most_similar(\"illusion\", topn=10)]\n",
    "print(f'Original model | Retrained model')\n",
    "print(' '*14, '|')\n",
    "[print(f'{wrds1:>14} | {wrds2}') for wrds1, wrds2 in zip(wrds1, wrds2)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model | Retrained model\n",
      "               |\n",
      "         black | black\n",
      "          navy | navy\n",
      "       colored | colored\n",
      "          grey | grey\n",
      "         cream | cream\n",
      "          gray | ivory\n",
      "         ivory | gray\n",
      "           red | brown\n",
      "         brown | red\n",
      "         beige | turquoise\n"
     ]
    }
   ],
   "source": [
    "wrds1 = [words[0] for words in model.wv.most_similar(\"white\", topn=10)]\n",
    "wrds2 = [words[0] for words in model_retrained.wv.most_similar(\"white\", topn=10)]\n",
    "print(f'Original model | Retrained model')\n",
    "print(' '*14, '|')\n",
    "[print(f'{wrds1:>14} | {wrds2}') for wrds1, wrds2 in zip(wrds1, wrds2)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some synonyms have moved up in the list, and some have newer meanings that were not in the top 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we have new mappings, such as for example \"white rabbit\", which is mentioned in the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41129318"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_retrained.wv.similarity('white', 'rabbit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model of creating vectors from *word2vec* words creates logical and understandable embeddings, over which you can perform some mathematical operations with meaningful results. At the same time, the training time of such a model is relatively short. Especially worth noting is the power provided by the ability to retrain an existing model for a specific class of tasks. At the same time, the specificity of the resulting embeddings is both an advantage and a disadvantage, since some familiar word senses may be absent due to the subject matter of the texts on which the model was trained."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
